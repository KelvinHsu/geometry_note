\newpage
\section{Theory of Variational Calculus}
\subsection{One-dimensional variational problems}
\begin{definition}
	Given a curve $\gamma:[a, b] \rightarrow \R^n$ with $\gamma(a) = P$ and $\gamma(b) = Q$, one can associate a number
	\begin{eqnarray}
		S[\gamma] = \int_{P}^{Q} L(x, \dot{x}) dt
	\end{eqnarray}
	to each function $L(x, \dot{x})$. Here the function $L(t, x, \xi): [a, b] \times U \times \R^n \rightarrow \R$, where $U$ is some neighborgood of $x$ and $\R^n$ is the tangent space, is said to be the \textbf{Lagrangian}. Also, $S[\gamma]$ is called the \textbf{action functional}.
\end{definition}

The main purpose of variational calculus is to find $\gamma$ which results in least $S[\gamma]$.

\begin{theorem}
	If action functional $S$ attains a minimum at $\gamma_0$ among all smooth curve from $P$ to $Q$, then the \textbf{variational derivative}
	\begin{eqnarray}
	\frac{\delta S}{\delta x^i} := \pardiff{L}{x^i} - \diff{ }{t}\left( \pardiff{L(t, x(t), \xi(t))}{\xi^i}  \right)_{\xi = \dot{x}(t)} = 0
	\end{eqnarray}
\end{theorem}

\begin{proof}
	For any function $\eta \in C^1([a, b], U)$ with $\eta(a) = \eta(b) = 0$, we have
	\begin{eqnarray}
	0 &&= \left.\diff{ }{\epsilon} S[\gamma_0 + \epsilon \eta] \right|_{\epsilon = 0}
	\nonumber\\
	&&= \int_{a}^{b} \left. \diff{}{\epsilon} L(t, x + \epsilon \eta, \dot{x} + \epsilon \dot{\eta}) \right|_{\epsilon = 0} dt
	\nonumber\\
	&&= \int_{a}^{b} \left[ \pardiff{L}{x^i}\eta^i(t) + \pardiff{L}{\xi^i} \dot{\eta}^i(t) \right]_{\epsilon = 0} dt
	\nonumber\\
	&&= \int_{a}^{b} \pardiff{L}{x^i}\eta^i(t)dt + \left. \pardiff{L}{\xi^i} \eta^i(t) \right|_a^b - \int_{a}^{b} \diff{ }{t} \left( \pardiff{L}{\xi^i} \right) \eta^i dt
	\nonumber\\
	&&= \int_{a}^{b} \frac{\delta S}{\delta x^i} \eta^i dt
	\end{eqnarray}
	Therefore, we can set $\eta^i = \dfrac{\delta S}{\delta x^i} f$, where $f$ is the cut-off function, i.e. $f \in C^{\infty}([a, b]), f(a) = f(b) = 0$ and $f>0$ on $(a, b)$. This enables us to conclude
	\[ \int_{a}^{b} f \left( \frac{\delta S}{\delta x^i} \right)^2 dt = 0 \implies \frac{\delta S}{\delta x^i} = 0. \]
\end{proof}

\begin{definition}
	The equation
	\begin{eqnarray}
	\pardiff{L}{x^i} - \diff{ }{t}\left( \pardiff{L}{\xi^i}(t, x, \dot{x})  \right) = 0
	\label{eq:E-L}
	\end{eqnarray}
	is called the \textbf{Euler-Lagrange equation}.
\end{definition}

\begin{definition}
	Write eq. (\ref{eq:E-L}) as \[\diff{ }{t}\left( \pardiff{L}{\xi^i} (t, x, \dot{x}) \right) = \pardiff{L}{x^i}, i = 1, \dots, n.\]	Define
	\begin{eqnarray}
		\text{(Momentum)} && p_i := \pardiff{L}{\xi^i}\\
		\text{(Force)} && f_i := \pardiff{L}{x^i}.
	\end{eqnarray}
	Then the Euler-Lagrange equation turns out to be Newton's law, $f_i = dp_i/dt$. Moreover, the energy is defined as
	\begin{eqnarray}
		(Energy) && E := \xi^i \pardiff{L}{\xi^i} - L.
	\end{eqnarray}
\end{definition}

\begin{example}
	\begin{enumerate}
		\item Let $L = L(x, \xi) = (1/2)m |\xi|^2 - U(x)$. Then we have
		\begin{eqnarray}
		&&\vkt{f} = \nabla^{(x)}L = -\nabla U \\
		&&\vkt{p} = \nabla^{(\xi)}L = m\xi = m\dot{x} \\
		&&E = m|\dot{x}|^2 - L = \frac{1}{2}m|\dot{x}|^2 + U.
		\end{eqnarray}
		
		\item Energy of the curve in a space with $dl^2 = g_{ij} dx^i dx^j$. $L$ is given by $L = (1/2)|\xi|^2 = (1/2)g_{ij} \xi^i \xi^j$. From this, momentum, force and energy can be calculated,
		\begin{eqnarray}
			&&p_k = g_{kj}\xi^j
			\nonumber\\
			&&f_k = \frac{1}{2}(\partial_k g_{ij}) \xi^i \xi^j
			\nonumber\\
			&&E   = L.
			\nonumber
		\end{eqnarray}
		Substituting them into Euler-Lagrange equation and then raising the index $k$ by $g_{km}$, we will see that
		\begin{eqnarray}
		&& g^{km} \left( dp_k/dt - f_k \right)
		\nonumber\\
		&&= \ddot{x}^m + g^{km} \left( \partial_i g_{jk} - \frac{1}{2} \partial_k g_{ij} \right) \dot{x}^i \dot{x}^j = 0
		\label{eq:geodesic_var}
		\end{eqnarray}
		Note that the term $g^{km} \left( \partial_i g_{jk} - (1/2) \partial_k g_{ij} \right)$ is symmetric in $i, j$, whence if we exchange the index and add it to the original one and then divide it by $2$, we will end up with the Christoffel symbol. That is, eq. (\ref{eq:geodesic_var}) is in fact, \[ \ddot{x}^m + \Gamma^m_{ij} \dot{x}^i \dot{x}^j = 0, \] the geodesic equation. Moreover, we can see that the geodesic curve is automatically parametrized by $t = \mu l$, where $\mu$ is some constant and $l$ is arclength.
		
		\item Length of a curve. Let $L = |\xi| = \sqrt{g_{ij}\xi^i \xi^j}$. In this case, the Euler-Lagrange equation will be
		\[ \diff{ }{t} \left( \frac{g_{kj} \xi^j}{\sqrt{g_{ij}\xi^i \xi^j}} \right) = \frac{ (\partial_k g_{ij}) \xi^i \xi^j}{2\sqrt{g_{ij}\xi^i \xi^j}}. \] If we choose the parameter of the curve to be multiple of arclength, then this equation will be reduced to the situation in the previous case.
	\end{enumerate}
\end{example}

\subsection{Conservation law}
If we compute the quantity $dE/dt$, we will find out that
\begin{eqnarray}
\diff{E}{t} &&= \diff{ }{t} \left( \dot{x}^i \pardiff{L}{\dot{x}^i} - L\right)
\nonumber\\
&&= \ddot{x}^i \pardiff{L}{\dot{x}^i} + \dot{x}^i \diff{ }{t}\pardiff{L}{\dot{x}^i} - \pardiff{L}{t} - \pardiff{L}{x^i}\dot{x}^i - \pardiff{L}{\dot{x}^i} \ddot{x}^i
\nonumber\\
&&= -\pardiff{L}{t}.
\nonumber
\end{eqnarray}
That is to say, the energy $E$ preserves if and only if $L$ is independent of $t$.

To further investigate this phenomenon, we consider the general case. Suppose there is an one-parameter group of transformations at $p \in U$, i.e. a group of transformations that consists of $S_{\tau}: U_p \subset U \rightarrow \R^n$ which are $C^{\infty}$-functions and have the properties: $S_0 = e, S_{\tau_1 + \tau_2} = S_{\tau_1} \circ S_{\tau_2}$ and $S_{-\tau} = S_{\tau}^{-1}$. We can associate the one-parameter group with the vecter field $\vkt{X}(p) = \diff{ }{\tau}\left. S_{\tau}(p) \right|_{\tau = 0}$.

\begin{definition}
	The one-parameter group $\{S_{\tau}\}$ of transformation preserves $L(x, \xi)$ if
	\begin{eqnarray}
		\diff{ }{\tau} S_{\tau} L(x, \xi) = \diff{ }{\tau}L(S_{\tau}(x), S_{\tau *}(\xi)) = 0, \forall \xi.
		\label{cond:preserve_L}
	\end{eqnarray}
\end{definition}

\begin{theorem}
	(E. Noether) If $L$ is preserved by $S_{\tau}$ generated by $\vkt{X}$, then on any extremal of $L$ (i.e. the curve extremize $S[\gamma]$) \textbf{the momentum in the $\vkt{X}$ direction} is conserved, i.e. the quantity $X^ip_i$ is a constant.
	\label{thm:noether_inv}
\end{theorem}
\begin{proof}
	Let $x \in \R^n$ be such that $\vkt{X}(x) \neq 0$. We can find a neighborhood of $x$ in which there exists a coordinate $y^1, \dots, y^n$ such that $S_{\tau}(y^1, \dots, y^n) = (y_1 + \tau, y^2, \dots, y^n)$. Since by the hypothese $S_{\tau}$ preserves $L$, it follows that change in $y^1$ doesn't effect the value of $L$, i.e. \[ \pardiff{L(y, \dot{y})}{y^1} \equiv 0. \] From Euler-Lagrange equation, we can observe \[ \diff{ }{t} \left( \pardiff{L}{\dot{y}^1} \right) = \pardiff{L(y, \dot{y})}{y^1} \equiv 0. \] But note that the term $\partial L/ \partial \dot{y}^1$ is in fact, with respect to the original coordinate $(x^1, \dots, x^n)$, $X^i(\partial L/ \partial x^i)$. This gives the wanted conclusion.
\end{proof}
\begin{proof}[Proof provided by Wang]
	\begin{eqnarray}
		\diff{ }{t} (X^i p_i) &&= \diff{ }{t} (X^i \pardiff{L}{\xi^i})
		\nonumber\\
		&&=\diff{X^i(x)}{t} \pardiff{L}{x^i} + X^i(x) \diff{ }{t} (\pardiff{L}{\xi^i})
		\nonumber\\
		&&=\pardiff{X^i}{x^j} \dot{x}^j \pardiff{L}{x^i} + X^i \pardiff{L}{x^i} = 0
		\nonumber
	\end{eqnarray}
\end{proof}

\begin{example}
	(2-particle system in $\R^3$, see \S 32.2 example (c) + (d)) In this case, the Lagrangian is given by
	\begin{eqnarray}
		L = \sum_{i = 1}^{3} \frac{1}{2}m_i|\dot{x}_i|^2 - \frac{1}{2} V(x_i, x_j)
		\nonumber
	\end{eqnarray}
	Note that this is in fact a $3n = 6$ dimensional problem, since each particle has $3$ coordinates. Since the potential term is translation-invariant, we can further deduce that $V$ depends only on $x_i - x_j$.
	
	\begin{corollary}
		$P_{\text{total}} = \sum_{i = 1}^{3} m_i \dot{x}_i \in \R^3$ is constant in $t$.
		\label{cor:const_momentum}
	\end{corollary}
	\begin{proof}
		Suppose $S_{\tau}$ only performs a translation of $\tau$ in $x^1$ direction, i.e. $x^1 \mapsto x^1 + \tau$ and $ x^i \mapsto x^i, i = 2, 3$. Therefore $S_{\tau}$ induces a vector field $X = (1, 0, 0; 1, 0, 0; 1, 0, 0)^{T}$ in $\R^6$. From Thm. \ref{thm:noether_inv} it follows that $P^1_{\text{total}} = \sum_{i = 1}^{3} m_i \dot{x}^1_i = X^ip_{i}$ is constant. We can deduce $P^i_{\text{total}}, i = 2, 3$ in a similar manner. The wanted result then follows.
	\end{proof}

	By Cor. \ref{cor:const_momentum} we have known that $m_1\dot{x}_1 + m_2\dot{x}_2 = \vkt{c}$ is constant. Now we may assume $\vkt{c} = 0$ and that $m_1 x_1 + m_2 x_2 = 0$, just by choosing an appropriate frame. It follows that $x_2 = -(m_1/m_2)x_1$ and thus
	\[ V(x_1, x_2) = V(x_1 - x_2) = V(1+\frac{m_1}{m_2}x_1) =: U(x_1) \]
	In this case, the Euler-Lagrange equation is reduced to $1$-particle case
	\[m^* \ddot{x}^{\alpha} = - \pardiff{U(x)}{x^{\alpha}}, \alpha = 1, 2, 3.\]
	If, in addition, $L$ is SO$(3)$-invariant, then $V(x_1, x_2) = V(|x_1 - x_2|)$. From this, we have  $x \parallel -\nabla U(x)$, and the angular momentum $[x, p] = m[x, \dot{x}]$ is constant $(\because [x, \dot{x}]' = 0)$. That is to say, the $L$ represents the centripetal force field and therefore describes a plane motion. On the other hand, as we have concluded in the begining of this subsection, $E = (1/2)m^* |\dot{x}|^2 + U$ will be constant in any trajectory if $L$ is independent of $t$. 
\end{example}

\subsection{Hamiltonian formalism}

\begin{definition}
	(Legendre transformation) The change of the coordinate from $(x, \xi)$-system (tangent bundle $TS$) to $(x, p)$-system (cotangent bundle $T^* S$) is called a \textbf{Legendre transformation}. One says that $L$ is \textbf{non-singular} if its Legendre transformation is locally invertible, namely
	\[\det(\pardiff{p_{\alpha}}{\dot{x}^{\beta}}) = \det\left( \frac{\partial^2 L}{\partial \dot{x}^{\alpha}  \partial \dot{x}^{\beta}} \right) \ne 0;\]
	furthermore, it is strongly non-singular if the equations $p_{\alpha} = \partial L(x, \xi)/\partial \xi^{\alpha}, \alpha = 1, \dots, n,$ uniquely determine $\xi = \dot{x} = v(x, p) \in C^{\infty}$.
\end{definition}

\begin{definition}
	The space with coordinates $(x, p)$ is called the \textbf{phase space} for $L$. The energy re-coordinatized with respect to $(x, p)$ is named \textbf{Hamiltonian}, $H(x, p) := E(x, \xi) = pv - L(x, v(x, p))$, where $pv = p_i \dot{x}^i$.
\end{definition}

\begin{theorem}
	(Hamilton) Let $L$ be strongly non-singular. Then there exists an equivalence between the following two systems,
	\begin{eqnarray}
		\begin{pmatrix}
			\dot{p} = \pardiff{L}{x}\\
			p = \pardiff{L}{\xi}\\
			\text{in }(x, \xi) \text{ coordinate}
		\end{pmatrix}
		\cong
		\begin{pmatrix}
			\dot{p} = -\pardiff{H}{x}\\
			\dot{x} = \pardiff{H}{p}\\
			\text{in }(x, p) \text{ coordinate}
		\end{pmatrix}
	\end{eqnarray}
\end{theorem}

\begin{proof}
	(Sufficiency) Starting from Euler-Lagrange equation and $p = \partial L/ \partial v$, where $v = \dot{x}$, we have
	\begin{eqnarray}
		&&-\pardiff{H}{x} = -\pardiff{ }{x} (pv - L) = - p \pardiff{v}{x} + \pardiff{L}{x} + \pardiff{L}{v}\pardiff{v}{x} = \pardiff{L}{x} = \dot{p}
		\nonumber\\
		&&\pardiff{H}{p} = \pardiff{ }{p} (pv - L) = v + p \pardiff{v}{p} - \pardiff{L}{v} \pardiff{v}{p} = v = \dot{x}.
		\nonumber
	\end{eqnarray}
	Note that the definition of $p$ and E-L equation have been used, and $x$ and $p$ are treated as independent variables.
	
	(Necessity) Starting from the Hamiltonian equations, we have
	\begin{eqnarray}
		&&\pardiff{L}{x} = \pardiff{ }{x}(p\dot{x} - H) = \dot{x} \pardiff{p}{x} - \pardiff{H}{x} - \pardiff{H}{p} \pardiff{p}{x} = \dot{p}
		\nonumber\\
		&&\pardiff{L}{\dot{x}} = \pardiff{ }{\dot{x}}(p\dot{x} - H) = \pardiff{p}{\dot{x}} \dot{x} + p - \pardiff{H}{p} \pardiff{p}{\dot{x}} = p
		\nonumber
	\end{eqnarray}
\end{proof}

\begin{corollary}
	Along any \textbf{trajectory} (or extremal of the energy level) $(x(t), p(t))$ in $2n$-dimensional phase space (i.e solution to the Hamiltonian equations) $H$ is constant (since $H$ is constant $\iff E$ is constant).
\end{corollary}

\begin{theorem}
	(Maupertuis' Principle) Let $H(x, p)$ be a time-independent Hamiltonian. Then any trajectory $(x(t), p(t))$ extremizing the action $S = \int L dt = \int (p\dot{x} - L) dt$ also extremizes the truncated action
	\[ S_0 = \int p\dot{x} dt = \int p dx. \]
\end{theorem}
\begin{proof}
	If the trajectory $(是p(t))$ extremize $\int (p\dot{x} - H) dt$ over a class of curves with energy level $E$, then it certainly extremizes $\int (p\dot{x} - E) dt$ over a smaller class. However, $\int E dt$ is a constant, whence it also extremizes $S_0 = \int p\dot{x} dt$.
\end{proof}


%%%%%% 12/14 %%%%%%%
\subsection{Geometric theory of phase space ($T^*\R^n$)}
Consider the gradient flow satisfying
\[\dot{y} = \nabla F(y(t))\]
with a given non-degenerate metric $g_{ij}$, which is not necessarily symmetric. Note that the gradient $\nabla$ is defined as \[ \nabla F := (dF)^\#, \] where $dF = F_i dy^i$ and thus $(dF)^\# = F^i \partial_{y^i}$, whence the gradient is written as $\nabla F = g^{ij} (\partial F/ \partial y^j) \partial_{y^i}$.

\begin{remark}
	The metric used to raise an index must be placed in front of the tensor whose index is being raised to avoid confusions.
\end{remark}

\begin{lemma}
	For any function $h(y)$, \[ \dot{h} := \diff{h(y(t))}{t} \equiv \inner{\nabla F}{\nabla h}, \] along the integral curve $y(t)$ of $\nabla F(y)$.
\end{lemma}
\begin{proof}
	\begin{eqnarray}
		\dot{h} &&= \diff{ }{t} h(y(t))
		\nonumber\\
		&&= dh(\dot{y}) = dh(\nabla F)
		\nonumber\\
		&&= \pardiff{h}{y^i} g^{ij} \pardiff{F}{y^i}
		\nonumber\\
		&&= \inner{dh}{dF} = \inner{\nabla h}{\nabla F}
		\nonumber
	\end{eqnarray}
	or
	\begin{eqnarray}
		&&\pardiff{h}{y^i} g^{ij} \pardiff{F}{y^i}
		\nonumber\\
		&&= h_i g^{ij} F_j
		\nonumber\\
		&&= h_i F^i
		\nonumber\\
		&&= g_{ij} h^j F^i = \inner{\nabla F}{\nabla h}.
		\nonumber
	\end{eqnarray}
\end{proof}

Now we set $m = 2n$ and let $g_{ij}$ be non-degenerate skew-symmetric, i.e. $g_{ij} = -g_{ij}, \det(g_{ij}) = g \neq 0$. Define the $2$-form
\[ \Omega := \sum_{i<j} g_{ij} dy^i \wedge dy^j. \]

\begin{lemma}
	If $g>0$, then
	\[\frac{1}{n!}\Omega^n = \sqrt{g} dy^1 \wedge \dots \wedge dy^{2n}.\]
	In fact, $\sqrt{g}$ is a polynomial in $g_{ij}$, called the \textbf{Pfaffian}.
\end{lemma}
\begin{proof}
	Fix $p \in \R^{2n} \simeq \mathrm{T}_{p}R^{2n}$. From \emph{the principal axis theorem for skew-symmetric axis} in linear algebra, we have that, with respect to a coordinate system $(z_1, \dots, z_{2n}) = (x^1, p_1, \dots. x^n, p_n)$, $y = Az, A \in \mathrm{SO}(2n)$ and
	\begin{eqnarray}
		(\tilde{g}_{ij}(p)) = A^{t}(g_{ij}(p)) A = 
		\begin{pmatrix}
			D_1 &&     &&    	 &&    		&&		\\
			    && D_2 &&        &&	   		&&		\\
			    &&     && \ddots &&			&&		\\
			    &&	   && 		 && D_{n-1} &&		\\
			    &&     &&        && 		&&  D_n
		\end{pmatrix},
	\end{eqnarray}
	where each $D_i, i = 1, \dots, n$ is of the form
	\[ D_i =
	\begin{pmatrix}
				 0&&	\lambda_i\\
		-\lambda_i&&			0\\
	\end{pmatrix}.\]
	Therefore, in this particular coordinate system, the differential $2$-form takes the form $\Omega = \sum_{i = 1}^{n} \lambda_i dx^i \wedge dp_i$. Finally,
	\begin{eqnarray}
		\Omega^n = \Omega \wedge \dots \wedge \Omega = n! \left(\prod_{i = 1}^{n} \lambda_i \right) dx^1 \wedge dp_1 \wedge \dots \wedge dx^n \wedge dp_n.
	\end{eqnarray}
	Note that $g = \lambda_1^2 \dots \lambda_n^2$. This lemma hence follows.
\end{proof}

\begin{definition}
	$\R^{2n}$ with coordinate $(x^i, p_i)_{i = 1}^{n}$ such that $\Omega = \sum_i dx^i \wedge dp_i$ (i.e. $\lambda_i = 1$) is called an abstract phase space. This coordinate $(x^i, p_i)_{i = 1}^{n}$ is said to be canonical coordinate. In the phase space, the differential equation $\dot{y} = \nabla H(x^i, p_i)$ generating the gradient flow becomes Hamitonian equations. Namely, \[ \dot{y} = \nabla H(x^i, p_i) \iff \dot{x}^i = \pardiff{H}{p_i}, \dot{p}_i = -\pardiff{H}{x^i}.\]
\end{definition}

\begin{definition}
	(The Poisson Bracket) \[\{ f, g \} := \inner{\nabla f}{\nabla g} \equiv g_{ij} f^i g^i = \sum_{i = 1}^{n} \left( \pardiff{f}{x^i} \pardiff{g}{p_i} - \pardiff{f}{p_i} \pardiff{g}{x^i} \right). \]
	Note that we have assumed the condition for abstract phase space in the last equality.
\end{definition}

\begin{fact}
	For the phase space, we have the following properties:
	\begin{enumerate}
		\item $\{ \cdot, \cdot\}$ is $\R$-linear and skew-symmetric.
		\item The Poisson bracket statisfies Jacobi identity.
		\item Leibniz's rule: $\{fg, h\} = f\{g, h\} + g\{ f, h\}$.
		\item $\nabla \{f, g\} = - [\nabla f, \nabla g]$, where $[ \cdot, \cdot ]$ denotes the Lie bracket.
	\end{enumerate}
\end{fact}
\begin{proof}
	1. and 3. come directly from the definition. Moreover, since the mapping $f \mapsto \nabla f$ is a monomorphism from the set of smooth functions to vector fields and thus 4. implies 2., we need only prove 4., which can be verified by direct computation.
\end{proof}

Instead of going through tedious computations, we can give another proof that Poisson bracket forms Lie algebra by employing the following theorem:

\begin{theorem}
	(Darboux) Given a skew-symmetric metric $g_{ij}$, the set of smooth functions $f(x, p)$ with Poisson bracket ${ \cdot , \cdot}$ forms a Lie-algebra if and only if $d\Omega = 0$ (i.e. sympletic), if and only if locally an abstract phase space.
	\label{thm:darboux}
\end{theorem}
\begin{proof}[Proof for the first iff.] The Jacobi identity holds if and only if
	\begin{eqnarray}
		&&\{ \{ f_1, f_2 \}, f_3 \} + \{ \{ f_2, f_3 \}, f_1 \} + \{ \{ f_3, f_1 \}, f_2 \} = 0
		\nonumber\\
		\iff && g^{pq} \partial_q g^{ij} \left(\partial_p f_1 \partial_i f_2 \partial_j f_3 + \partial_p f_2 \partial_i f_3 \partial_j f_1 + \partial_p f_3 \partial_i f_1 \partial_j f_2 \right) = 0
		\nonumber\\
		\iff && \partial_p f_1 \partial_i f_2 \partial_j f_3 \left( g^{pq} \partial_q g^{ij} + g^{iq} \partial_q g^{jp} + g^{jq} \partial_q g^{pi} \right) = 0
		\nonumber
	\end{eqnarray}
	Multiply by $g_{rp}g_{sj}g_{ti}$ and sum over $p, i, j$.
	\[ \iff (d\Omega)_{rst} = \partial_{r} g_{ts} - \partial_{s} g_{tr} + \partial_{t} g_{sr} = 0. \]
\end{proof}

\begin{lemma}
	(Poincar\'{e}'s lemma) On a disk (or contractible open set) $D \subset \R^N$, $d\omega = 0, \omega \in \Lambda^{p} \implies \omega = d\eta$ for some $\eta \in \Lambda^{p-1}$
	\label{lem:poincare}
\end{lemma}
\begin{proof}[Sketch of proof.]
	This can be derived from Cartan's Homotopy formula (See Ex. \ref{thm:cartan_homo} of  \ref{sec:hw11}).
	\begin{eqnarray}
		&&L_{X} = \iota_X d + d \iota_X
		\nonumber\\
		\implies &&\diff{ }{t} \left(f^*_t \omega\right)  = L_X(\omega) = \iota_X d\omega + d\iota_x(\omega) = d\iota(\omega).
		\nonumber\\
		\implies && \int \diff{ }{t} \left(f^*_t \omega\right) = \int d \iota_X(\omega)
	\end{eqnarray}
\end{proof}

\begin{proof}[Proof for second iff of Darboux's theorem.]
	Here we use Moser's procedure, namely
	\begin{lemma}
		If $\omega_t$ is sympletic $d\omega_t = 0$ for $t \in [0, 1]$ and $\diff{ }{t}\omega_t = d\sigma_t$ for some $\sigma_t$ (i.e. )
	\end{lemma}
\end{proof}


%%%%%% 12/16 %%%%%%
\begin{remark}
	In the text, the Poisson bracket is defined as 
	\begin{eqnarray}
		\inner{\nabla f}{\nabla g} := g^{ij} f_i g_j,
	\end{eqnarray}
	while the usual convention is
	\begin{eqnarray}
		\inner{\nabla f}{\nabla g} := g_{ij} f^i g^j.
	\end{eqnarray}
	Since $g_{ij}$ and $g^{ij}$ are inverse matrices to each other, this results in that, under the phase space, 
	\[ \inner{\nabla f}{\nabla g} = - \sum_i \left( \pardiff{f}{x^i} \pardiff{g}{p_i} - \pardiff{g}{x^i} \pardiff{f}{p_i} \right), \]
	which differs from the usual expression with a minus sign.
\end{remark}

\begin{definition}
	$f$ is called a (first) integral fuction if $\dot{f} = 0$ along any trajectories. i.e. $\{f, H\} = 0$.
\end{definition}
\begin{corollary}
	Integral functions form a Lie-subalgebra of the Lie-algebra of smooth functions.
\end{corollary}
\begin{proof}
	This is implied by Jacobi identity.
\end{proof}

\begin{definition}
	Canonical transformation $\Phi$ is a transformation preserving the form $\Omega$, i.e. $\Phi^* \Omega = \Omega$.
\end{definition}

\begin{theorem}
	Every one-parameter group of canonical transformations $\Phi_t$ is locally generated by a Hamiltonian vector field, i.e. $\Phi = d \Phi_t/ dt|_{t = 0} = \nabla H$ for some Hamiltonian $H$.
	\label{thm:1-para_cano_transf}
\end{theorem}
\begin{proof}
	content...
\end{proof}

\subsection{Lie algebra of Sympletic transformations}
Locally in a Darboux chart, $X := \nabla H = (\pardiff{H}{p_1}, - \pardiff{H}{x^1}, \dots, \pardiff{H}{p_n}, - \pardiff{H}{x^n})$.
\begin{definition}
	A sympletic transformation $\Phi$ is a \emph{linear canonical transformation} on $\R^{2n}$ if $\Phi$ is linear, and if $\Phi^* \Omega = \Omega$, where $\Omega = g_{ij} dy^i \wedge dy^j = \sum_{i = 1}^{n} dx^i \wedge dp_i$.
\end{definition}

For the group of sympletic transformation $\mathrm{Sp(n)}$, there exists a matrix $K \in M_{2n}(\C)$, or $T_{e}\mathrm{Sp}(n)$, such that $X(y) = Ky$ by Thm. \ref{thm:1-para_cano_transf} and the definition. Since $\nabla H = X(y) = Ky$ is a first order differential equation, we can deduce the general solution of Hamiltonian $H$ is a quadratic equation, namely
\[ H = \frac{1}{2} \sum_{i, j}^{n} \left( a_{ij}x^ix^j + 2b_{ij} x^ip_j + c_{ij}p_ip_j \right), \]
with $a_{ij} = a_{ji}, c_{ij} = c_{ji}$. From this we can determine the matrix $K$,
\[K=
\begin{pmatrix}
B^t  &&  C \\
-A   && -B 
\end{pmatrix}\]
Hence we have determined the Lie-algebra $\mathrm{sp}(n)$.

\subsection{Lagrange Surface}
Recall that, given $H = H(x, p)$ and any function $f(x, p, t)$, we have
\[ \dot{f} = \pardiff{f}{t} + \{ f, H \}. \]
If we set $f = E = H$, then $\dot{H} = \pardiff{H}{t} + \inner{\nabla H}{\nabla H} = \pardiff{H}{t} = 0$ since the metric is skew-symmetric and $H(x, p)$ time-independent. Now, if $H(x, p, t)$ is time-dependent, we formulate the following definition.

\begin{definition}
	(Extended phase space when $H$ is time-dependent) Introducing $t$ and $E$ as variables $x^{n+1}$ and $p_{n+1}$, respectively, we will then end up with a new Hamiltonian system $\tilde{H}(x, p, t, E) = H(x, p, t) = E$, since
	\begin{eqnarray}
		&&\pardiff{\tilde{H}}{p_{n+1}} = \pardiff{\tilde{H}}{E} = -1 = -\dot{t} = -\dot{x}_{n+1}
		\nonumber\\
		&&\pardiff{\tilde{H}}{x^{n+1}} = \pardiff{\tilde{H}}{t} = \dot{E} = \dot{p}_{n+1}.
		\nonumber
	\end{eqnarray}
	In this extented $\R^{2n+2}$ phase space we get
	\[ \tilde{\Omega} = \Omega - dt \wedge dE = \sum_i dx^i \wedge dp_i - dt \wedge dE. \]
\end{definition}

\begin{definition}
	(Lagrange surface) A surface $\Gamma$ of half dimension of the underlying phase space with $\Omega|_{\Gamma} = 0$ is called a \textbf{Lagrange surface}. For example, $x^i = 0$ or $p_i = 0$.
\end{definition}
One can observe that if $\Gamma$ is Lagrangian, then the image under any canonical transformation $\Phi(\Omega)$ is Lagrangian as well (as one can notice, the surface $p_i = 0$ is the image of $x^i = 0$ under the canonical mapping $(x, p) \mapsto (p, -x)$).

In typical cases, a Lagrange surface is the \emph{graph} for a differential for some function with respect to the Darboux chart. To see such graph is Lagrangian, consider $\Gamma = \{(x, d\phi)\} = \{(x, p_i = \pardiff{\phi}{x^i})\}$. Then,
\[\sum dx^i \wedge dp_i = \sum dx^i \wedge d\left(\pardiff{\phi}{x^i}\right) = \sum \frac{\partial^2 \phi}{\partial x^i \partial x^j} dx^i \wedge dx^j, \]
which must vanish since the wedge product is skew-symmetric while the second-order derivatives are symmetric.

In fact, this typical case composes all of the Lagrange surface.
\begin{theorem}
	Every Lagrange surface $\Gamma$ is locally the graph for differential of some function.
\end{theorem}
\begin{proof}
	Locally we have $\Omega = d\eta$ for some one-form $\eta$, e.g. $\eta = -p_i dx^i$ (Darboux's theorem (Thm. \ref{thm:darboux}) and Poincar\'{e}'s lemma (Lemma. \ref{lem:poincare})). By hypothesis, $d(\eta|_p)$ at some point $p$ (i.e. locally). By Poincar\'{e}'s lemma again we have $\eta|_p = d\phi$ for some function (0-form) $\phi$. Therefore we may assume $\Gamma$ is the graph of $d\phi$ over $x$,
	\[ d\phi = \pardiff{\phi}{x^i} dx^i = \eta|_p  = -p_i dx^i \implies p_i = - \pardiff{\phi}{x^i}. \] 
\end{proof}

For \emph{classical} Hamiltonian systems, this theorems can give an alternative definition.
\begin{corollary}
	\begin{enumerate}
		\item In the phase space with $H(x, p)$, $\Gamma^n$ ($n$ denotes the dimension) is a Lagrange surface if and only if $\forall Q \in \Gamma^n$ the truncated action $S_0(P) = S_0[\gamma] = \int_{\gamma} pdx$ depends only on the initial point $P$ but not on the choice of curve $\gamma$ joining $P$ and $Q$.
		\item In the extended phase space with $H(x, p, t)$, $\Gamma^{n+1}$ is a Lagrange surface if and only if the truncated action $S_0(P) = S_0[\gamma] = \int_{\gamma} pdx -Edt$ depends \textbf{locally} only on the initial point $P$ but not on the choice of curve $\gamma$ joining $P$ and $Q$.
	\end{enumerate}
	\label{cor:classical_def_lag}
\end{corollary}

\begin{definition}
	In the second case of Cor. \ref{cor:classical_def_lag} $S_0(P)$ is called the \textbf{action of a trajecory bundle} and the equation
	\begin{eqnarray}
		0 = \pardiff{S}{t} + E(x, p, t) = \pardiff{S}{t} + H(x, \pardiff{S}{x}, t)
	\end{eqnarray}
	is said to be the \textbf{Hamilton-Jacobi} equation. 
\end{definition}

\begin{theorem}
	Given $H(x, p)$ and $\mathcal{S} := \{H = \text{const.}\}$
	\begin{enumerate}
		\item $\nabla H = \left( \pardiff{H}{p}, -\pardiff{H}{x} \right) \in T_P \mathcal{S}$.
		\item $\inner{\nabla H}{\xi} = 0, \forall \xi \in T_P \mathcal{S}$.
		\item If $\Gamma^n$ is a Lagrange surface with constant $H$, then any trajectory touching $\Gamma^n$ lies in $\Gamma^n$ entirely.
	\end{enumerate}
\end{theorem}
\begin{proof}
	For 1. and 2., one first observe that $\xi \in T_p\mathcal{S} \iff \xi^i \partial H / \partial y^i$. Therefore, \[ \inner{\nabla H}{\xi} = g_{ij} g^{ik}\pardiff{H}{y^k} \xi^j = -  \pardiff{H}{y^j}\xi^j = 0. \]
	In particular, we have $\inner{\nabla H}{\nabla H} = 0$.
	
	For 3., let $P$ be a point of intersection and suppose $T_P\mathcal{S}$ has max dimension, i.e. $n$. Then 2. implies that $\nabla H(P) \in T_P\mathcal{S} $ for all such $P$. Hence, if $\gamma$ is a trajectory with $\gamma(0) = p$, then $\dot{\gamma} = \nabla H \in T_P\mathcal{S} \implies \gamma \subset \Gamma^n.$
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%% Exercises %%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Homework 11} \label{sec:hw11}
\begin{enumerate}
	\item (Ex. in pp. 324) Let
	\begin{eqnarray}
	L &&= L(t, x, \dot{x}, \ddot{x}, \dots, x^{(k)});
	\nonumber\\
	S[\gamma] &&= \int_{\gamma} L(t, x, \dot{x}, \ddot{x}, \dots, x^{(k)}) dt.
	\end{eqnarray}
	Prove that the extremals of the functional $S[\gamma]$ satisfy the Euler-Lagrange equation
	\begin{eqnarray}
		\frac{\delta S}{\delta x^i} := \pardiff{L}{x^i} - \diff{}{t}\pardiff{L}{\dot{x}} + \diff[2]{ }{t} \pardiff{L}{\ddot{x}} - \cdots + (-1)^k \diff[k]{ }{t} \pardiff{L}{x^{(k)}} = 0.
	\end{eqnarray}
	
	\begin{proof}
		Let $C$ be the set of curves satisfying the boundary condition $x^i(a)$, $x^i(b)$, $\dots$, $[x^{k-1}]^i(a)$, $[x^{k-1}]^i(b)$, $i = 1, \dots, n$. Suppose $\gamma_0$ extremizes $S[\gamma]$ over $C$. Let $\eta: y^i(t), a \leq t \leq b,$ be an arbitrary curve with $y^i(a) = 0 = y^i(b), \dots, [y^{k-1}]^i(a) = 0 = [y^{k-1}]^i(b)$, so that we have \[ \left. \diff{ }{t} S[\gamma_0 + \epsilon \eta] \right|_{\epsilon = 0}  = 0.\] Therefore,
		\begin{eqnarray}
			0 = \int_{a}^{b} \pardiff{L}{x^i} y^i + \pardiff{L}{\dot{x}^i} \dot{y}^i + \dots + \pardiff{L}{x^{(k), i}} y^{(k), i} dt,
			\label{eq:extrema_cond}
		\end{eqnarray}
		where the summation over $i$ is understood to take place, and $x^{(j), i}$ denotes the $i$-th component of $j$-th derivative of $x$. Note that
		\[ \int \pardiff{L}{x^{(j), i}} y^{(j), i} = (-1)^{j} \int_{a}^{b} y^i \diff[j]{ }{t} \pardiff{L}{x^{(j), i}}.\]
		Finally from Eq. (\ref{eq:extrema_cond}), we have
		\begin{eqnarray}
			\int_{a}^{b} y^i \left( \pardiff{L}{x^i} + \sum_{j = 1}^{k} (-1)^{j} \int_{a}^{b} y^i \diff[j]{ }{t} \pardiff{L}{x^{(j), i}} \right) = 0.
		\end{eqnarray}
		
		Set $\eta: y^i = f(t) \psi_i$, where $f$ is a cutoff function (i.e. $f(a) = 0 = f(b)$ and $f > 0$ on $(a, b)$) and $\psi_i = \pardiff{L}{x^i} + \sum_{j = 1}^{k} (-1)^{j} \int_{a}^{b} y^i \diff[j]{ }{t} \pardiff{L}{x^{(j), i}}$. Then the result follows from $\int_{a}^{b} f \psi_i^2 dt= 0$.
	\end{proof}
	
	\item (Claim in pp. 335) For $L = (1/2)mv^2 - U(r)$ and $U(r) = \alpha/r$ or $U(r) = \alpha r^2$, there exists a region of 6-dimensional space coordinatized by $x, \dot{x}$, which is completely filled by closed orbits (i.e. for every $(x_0, \xi_0)$ in the region there is a closed orbit $x = x(t)$ such that for some $t_0$ we have $x_0 = x(t_0), \xi_0 = \dot{x}(t_0)$). These regions are given by
	\begin{eqnarray}
		E < 0, \alpha < 0&& \text{ for } U = \frac{\alpha}{r}
		\nonumber\\
		E > 0, \alpha > 0 && \text{ for } U = \alpha r^2.
		\nonumber 
	\end{eqnarray}
	\begin{proof}
		From the hint in the text one can derive the integral
		\begin{eqnarray}
			\int d\phi = \int \frac{|M|dr}{ r^2 \sqrt{2m(E - U_{eff})} },
		\end{eqnarray}
		with $U_{eff} = U(r) + |M|^2/2mr^2$, to determine the equation of the trajectory.
		\begin{enumerate}
			\item For the case $U(r) = \alpha / r$, we can substitue the potential term into the integral and get
			\begin{eqnarray}
				d\phi = \frac{dr / r^2}{\sqrt{\frac{2mE}{|M|^2} - \frac{2m\alpha}{|M|^2r} - \frac{1}{r^2}}}。
			\end{eqnarray}
			Perform the change of variable $u = 1/r$ and set $A = 2mE/|M|^2, B = 2m\alpha/|M|^2$.
			\begin{eqnarray}
				d\phi = \frac{-du}{\sqrt{A - Bu -u^2}}.
			\end{eqnarray}
			Note that $-u^2 - Bu + A = -(u + B/2)^2 + A + B^2/4$. Let $v = 2u + b, dv = 2du$ and $k^2 = 4A+B^2$. Then,
			\begin{eqnarray}
				d\phi = \frac{-dv}{\sqrt{k^2 - v^2}}.
			\end{eqnarray}
			Integrate and get
			\begin{eqnarray}
				\phi = \arccos \left( \frac{v}{k} \right) + C,
			\end{eqnarray}
			for $-1 \leq v/k \leq 1$ and some constant $C$. If we give the boundary condition $\phi(v)|_{v = k} = \phi_0$, then we will have $C = \phi_0$. After some rearrangement and substitute back the constants, the equations turn out to be
			\begin{eqnarray}
				r(\phi) = \frac{-|M|^2/m\alpha}{1 - \sqrt{1 + 2E|M|^2 / m\alpha^2} cos(\phi - \phi_0)}.
			\end{eqnarray}
			This is of the form of a conic section in polar coordinate, $r = p/(1 - \epsilon \cos\phi)$. For $r(\phi )$ to be a closed orbit, or more precisely an ellipse, we shall request $p > 0$ and $\epsilon < 1$, which leads to the conclusion that closed orbits fill the region $E < 0, \alpha < 0$.
			
			\item For $U(r) = \alpha r^2$, by a similar deduction, we can reduce the problem to the integral
			\begin{eqnarray}
				d\phi = \frac{-u du}{\sqrt{-u^4 + Au^2 -B}},
			\end{eqnarray}
			with $A = 2mE/|M|^2, B = 2m\alpha/|M|^2$. After a series of change of variable and substitution back, we then have
			\begin{eqnarray}
				\phi = \frac{1}{2} \arccos\left(\frac{2u^2 - A}{\sqrt{A^2 - 4B}}\right) + C
			\end{eqnarray}
			Set the boundary condition $\phi = \phi_0$ when $u^2 = (\sqrt{A^2 - 4B} + A)/2$, which leads to $C = \phi_0$. Therefore,
			\[ \phi - \phi_0 = \frac{1}{2} \arccos\left(\frac{2u^2/A - 1}{\sqrt{1 - 4B/A^2}}\right),\]
			or
			\begin{eqnarray}
				r^2 = \frac{|M|^2/mE}{1 + \sqrt{1 - |M|^2\alpha/2mE^2} \cos 2(\phi - \phi_0)}.
			\end{eqnarray}
			This as well represents a conic section in polar coordinate.  By the condition for an ellipse we can draw the same conclusion but in the region $E > 0, \alpha > 0$.
		\end{enumerate}
	\end{proof}
	
	\item (Ex. 33.4:1) Consider the differential equation \[ \dot{u} = \pardiff{ }{x} \frac{\delta S}{\delta u}, \] on the space of functions $u(x)$ periodic with period $T$, and satisfying \[ \int_{x_0}^{x_0+T} u(x) dx = 0, \] where $S = S[u]$ is a functional of the form \[ S[u] = \int_{x_0}^{x_0+T} L(u, u', \dots) dx. \] Transform the differential equation into standard Hamiltonian form. (Hint: Work with the Fourier coefficients $u_n$ of $u$ determined by $u = \sum_{n = -\infty}^{\infty} u_n e^{(2 \pi i n x)/T} $.)
	
	\item (Ex. 25.3:3) For each vector field $X$ define a linear operator $\iota(X)$ on forms by
	\[ [\iota(X)\omega](X_1, \dots, X_{k-1}) = \omega(X, X_1, \dots, X_{k-1}), \] where $\omega$ is any form of rank $k$, and $X_1, \dots, X_{k-1}$ are arbitrary vector fields.\label{thm:cartan_homo}
	\begin{enumerate}
		\item Prove that $\iota(X)$ is \emph{anti-differentiation}, i.e.
		\[ \iota(X)(\omega_1 \wedge \omega_2) = (\iota(X)\omega_1) \wedge \omega_2 + (-1)^k \omega_1 \wedge (\iota(X)\omega_2), \]
		where $k$ is the rank of the form $\omega_1$.
		\item Establish the formula \[ \iota(X)d + d \iota(X) = L_X, \] where $L_X$ denotes the operation of taking the Lie derivative along the field $X$.
	\end{enumerate}
\end{enumerate}

\subsection{Homework 12}
\begin{enumerate}
	\item (Ex. 33.4:2) Suppose we have a Lagrangian $L$ depending on derivatives higher than the first: $ L = L(u, u', \dots, u^{(n)}), S[u] = \int Ldx. $ Then the Euler-Lagrange equation $\delta S/\delta u = 0$ for the extremals of the functional $S$ can be rewritten in Hamiltonian form as
	\begin{eqnarray}
		q'_i = \pardiff{H}{p_i}, && p'_i = \pardiff{H}{q_i}, \hspace{0.3 in} \hbox{$i = 1, \dots, n,$}
		\nonumber
	\end{eqnarray}
	where
	\begin{eqnarray}
		q_i = u^(i-1), && p_i = \pardiff{L}{u^{(i)}} + \sum_{s = 1}^{n - i} (-1)^s \diff[n]{ }{x} \pardiff{L}{u^{(i+s)}}, \hspace{0.3 in} \hbox{$i = 1, \dots, n,$}
		\nonumber
	\end{eqnarray}
	provided the equations $p_n = \partial L/\partial q'_n$ can be uniquely solved for $q_n' = u^{(n)}$.
	
	\item
	\begin{enumerate}
		\item (Ex. 34.4.1) With each vector field $X$ on configuration space (i.e. on the space with coordinate $x$), we associate a function $F_X$ on phase space by defining $F_X = p_i X^i$. Show that $\{F_X, F_Y\} = -F_{[X, Y]}$.
		\item (Ex. 34.4.2) Let $f = f(x)$ be a function on phase space independent of momentum $p$. Show that $\{ f, F_X \} = \partial_X f$.
	\end{enumerate}

	\item (Ex. 34.4.7) Let $(g_{ij})$ be a non-singular skew-symmetric matrix. Such a matrix defines in the usual way a \emph{skew} scalar product on the $2n$-dimensional vector space $\R^{2n}$. Prove that any subspace on which the restriction of this skew scalar product is identically zero, has dimension $\leq n$.
	
	\item (Ex. in 35.2, pp. 371) Suppose that in phase space $\R^{2n}$ we are given $n$ independent functions $f_1(x, p), \dots, f_n(x, p)$ (i.e. having linearly independent vector-gradients) which pairwise commute: $\{f_i, f_j\} = 0$. Show that the surface in $\R^{2n}$ defined by the $n$ equations $f_1 = 0, \dots, f_n = 0$ is Lagrange.
\end{enumerate}
